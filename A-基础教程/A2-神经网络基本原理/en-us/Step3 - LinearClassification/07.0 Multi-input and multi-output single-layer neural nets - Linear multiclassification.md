<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->
  
# Chapter 7 Multi-input and multi-output single-layer neural nets - Linear multi-classification

## 7.0 Linear multi-classification problem

### 7.0.1 Raising Questions

We have solved the Chu-Han Contention problem in BC and now look at the Three Kingdoms problem around 220 AD.

There are 140 sample data in the dataset, as shown in Table 7-1.

Table 7-1 Sample Data Sampling

|Sample number|$x_1=$Relative Longitude|$x_2=$Relative Latitude|$y=$Classification|
|---|---|---|---|
|1|7.033|3.075|3|
|2|4.489|4.869|2|
|3|8.228|9.735|1|
|...|...|...|...|
|140|4.632|9.014|1|

Meaning of the classification label values:

1. Cities of Wei: labelled as 1, blue dots in Figure 7-1
2. Cities of Shu: labelled 2, red dots in Figure 7-1
3. Cities of Wu : labelled 3, green dots in Figure 7-1

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/7/source_data.png" ch="500" />

Figure 7-1 Sample data visualization

Questions：

1. which country does it belong to when the relative latitude and longitude values are $(5,1)$?
2. Which country is it when the relative latitude and longitude values are $(7,6)$?
3. which country does it belong to when the relative latitude and longitude values are $(5,6)$?
4. Which country is it when the relative latitude and longitude values are $(2,7)$?

### 7.0.2 Multi-classification learning strategy

#### The difference between linear and non-linear multi-classification

Figure 7-2 shows the difference between linear and non-linear multi-classification.

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/7/linear_vs_nonlinear.png" />

Figure 7-2 Intuitive understanding of the difference between linear and non-linear multi-classification

The left side is linear multi-classification, and the right side is non-linear multi-classification. The difference between them is whether the sample points of different categories can be separated by a straight line. For neural networks, linear multiclassification can be solved using a single-layer structure, while non-linear multi-classification requires a two-layer structure.

#### The relationship between binary classification and multi-classification

We have learned about using neural networks to do binary classification, which does not work for multi-classification. In traditional machine learning, some binary classification algorithms can be directly generalized to multi-classification, but more often than not, we will use binary classification learners to solve multi-classification problems based on some basic strategies.

There are three ways to solve the multi-classification problem.

1. one-to-one approach
   
Train one classifier by keeping only two categories of data at a time. If there are $N$ categories, then $C^2_N$ classifiers need to be trained. For example, if $N=3$, we need to train $A|B, B|C, A|C$ classifiers.

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/7/one_vs_one.png" />

Figure 7-3 One-to-one approach

As shown on the far left of Figure 7-3, this two classifier only cares about classifying blue and green samples, regardless of the red samples, which means that only blue and green samples are fed into the network during training.
   
When the $(A|B)$ classifier tells you that it is class A, you need to go to the $(A|C)$ classifier and try again, and if it is also class A, then it is class A. If $(A|C)$ tells you it's class C, it's basically class C. It can't be class B. If you don't believe me, you can go to the $(B|C)$ classifier and test it again.

2. One-to-many approach
   
As in Figure 7-4, when dealing with one category, all other categories are temporarily considered as one category so that for the three-classification problem, three classifiers can be obtained.

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/7/one_vs_multiple.png" />

Figure 7-4 One-to-many approach

As in the leftmost figure, the red samples are treated as one class, the blue and green samples are mixed together as another category during training.

Three classifiers are called simultaneously, and the three results are combined to give the actual result.  For example, if the first classifier tells you it's a "red class", then it is indeed a red class; if it tells you it is anon-red class, you need to look at the result of the second classifier, green class or non-green class; and so on.

3. Many-to-many approach

Suppose there are 4 categories ABCD, we can count AB as one class and CD as one class, and train a classifier 1; then count AC as one class and BD as one class, and train a classifier 2.
    
The first classifier tells you class AB, and the second classifier tells you class BD, then do the " AND " operation, which is class B.

#### Multi-classification and multi-label

In multi-classification learning, although there are multiple categories, each sample belongs to only one category.

For example, if a picture has blue sky and white clouds and flowers and trees, there are two ways to label this picture.

- A picture labelled as "landscape" instead of "people" is a landscape picture, which is called classification.

- The picture is labeled as "blue sky", "white clouds", "flowers", "trees", etc. Such a task is not called multi-classification learning but multi-label learning, which we do not address here.
